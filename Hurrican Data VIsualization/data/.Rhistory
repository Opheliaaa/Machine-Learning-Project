names(df)=c('date','time','landfall','type','lat','long','category')
write.csv(df,"best_track_updated.csv")
View(df)
#Parsing Data for Best Track Line from NHC
best_track = fread("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt", blank.lines.skip = TRUE, header = FALSE, fill = TRUE)
#Create variable for recording category of hurricanes
best_track$category = vector()
best_track$category[best_track$V7 > 64] = 1
best_track$category[best_track$V7 > 83] = 2
best_track$category[best_track$V7 > 96] = 3
best_track$category[best_track$V7 > 113] = 4
best_track$category[best_track$V7 > 137] = 5
best_track$category[is.na(best_track$category)] = 0
View(best_track)
df=best_track[,-7:-21]
names(df)=c('date','time','landfall','type','lat','long','category')
write.csv(df,"best_track_updated.csv")
df=data.frame(name=c(1),ld=c(1))
df
df=data.frame(name=c(),ld=c())
df[1,]=list(1,2)
df=data.frame(name=c(),ld=c())
df[1,]=list(1,2)
df
df=data.frame(name=c(1),ld=c(1))
df[1,]=list(1,2)
df
df=data.frame(name=c(1),ld=c(1))
df[1,]=list(1,2)
df[2,]=list(2,3)
df
df=data.frame(name=c(),ld=c())
df[1,]=list(1,2)
df[2,]=list(2,3)
df
df=data.frame(name=c(1),ld=c(1))
df[1,]=list(1,2)
df[2,]=list(2,3)
df
df=data.frame(name=c(),ld=c())
df[1,]=list(1,2)
df[2,]=list(2,3)
df
df=data.frame(name=c(1),ld=c(1))
df[1,]=list(1,2)
df[2,]=list(2,3)
df
knitr::opts_chunk$set(echo = TRUE)
best_track_updated <- read.csv("best_track_updated.csv",header = TRUE)
get_landfall_date = function(name, year) {
name = tolower(name)
index = which(tolower(best_track_updated$time) == name)
start = index[which(substrRight(as.character(best_track_updated$date[index]), 4) == year)]
hurricane = grep("[A-Z]", best_track_updated$time)
end = hurricane[which(hurricane == start) + 1]
in_df = best_track_updated[start:(end-1), ]
in_df = in_df[-1, ]
in_date = (in_df$date[which(in_df$landfall == "L" & in_df$category > 0)])
in_date = as.Date(in_date, "%Y%m%d")
return(c(in_date))
}
get_landfall_date('nate',2017)
typeof(get_landfall_date('nate',2017)[0])
get_landfall_date('nate',2017)[0]
get_landfall_date('nate',2017)[1]
typeof(get_landfall_date('nate',2017)[1])
as.string(get_landfall_date('nate',2017)[1])
as.String(get_landfall_date('nate',2017)[1])
?as.character
as.character(get_landfall_date('nate',2017)[1])
ld=as.character(get_landfall_date('nate',2017)[1])
df=data.frame(name=c('a'),ld=c('1'))
df[1,]=c('nate',ld)
for (i in 1:0){
print('x')
}
for (i in 0:0){
print('x')
}
for (i in 0:0){
'c'+as.character(1)
'c'+as.character(1)
as.character(1)
'c'+1
'c'+1
'c'+toString(1)
paste('c',toString(1))
paste('c',toString(1),sep='')
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
best_track_updated <- read.csv("~/Desktop/hurricane/data/best_track_updated.csv",header = TRUE)
best_track_updated <- read.csv("best_track_updated.csv",header = TRUE)
get_landfall_date = function(name, year) {
name = tolower(name)
index = which(tolower(best_track_updated$time) == name)
start = index[which(substrRight(as.character(best_track_updated$date[index]), 4) == year)]
hurricane = grep("[A-Z]", best_track_updated$time)
end = hurricane[which(hurricane == start) + 1]
in_df = best_track_updated[start:(end-1), ]
in_df = in_df[-1, ]
in_date = (in_df$date[which(in_df$landfall == "L" & in_df$category > 0)])
in_date = as.Date(in_date, "%Y%m%d")
return(c(in_date))
}
landfall <- data.frame()
for (i in 1:100) {
df=data.frame()
ld=get_landfall_date(hurricane_names[i], dates[i])
name = hurricane_names[i]
for (i in 1:length(ld)){
df[nrow(df)+1, 1:2] = list(paste0(as.character(name), i), ld[i])
}
landfall = rbind(landfall, df)
}
library(maps); library(gridExtra); library(ggmap); library(ggplot2); library(plyr); library(raster); library(RColorBrewer); library(maptools); library(rgeos); library(sp); library(rgdal); library(geosphere); library(stringi); library(data.table)
#Parsing Data for Best Track Line from NHC
best_track = fread("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt", blank.lines.skip = TRUE, header = FALSE, fill = TRUE)
#Create variable for recording category of hurricanes
best_track$category = vector()
best_track$category[best_track$V7 > 64] = 1
best_track$category[best_track$V7 > 83] = 2
best_track$category[best_track$V7 > 96] = 3
best_track$category[best_track$V7 > 113] = 4
best_track$category[best_track$V7 > 137] = 5
best_track$category[is.na(best_track$category)] = 0
#Parsing Data for Watchzone from NHC
cities = read.table("../data/wwpts_us.txt", fill = TRUE, col.names = rep("V", 10))
#now clean up data to look like what we want
index_cities = grep("=", cities[, 2])
number_index_list = gregexpr("[0-9]", cities[,2])
number_index = which(sapply(number_index_list, "[[", 1) == 1)
reps = diff(number_index) - 1
code = cities[number_index, 7]
date = paste0(cities[number_index, 1], "/", cities[number_index, 2], "/", cities[number_index, 3])
name = cities[number_index, 5]
hour = cities[number_index, 4]
#get rid of improper coding
city = paste0(cities[index_cities, 2], cities[index_cities, 3], cities[index_cities, 4], cities[index_cities, 5], cities[index_cities, 6], cities[index_cities, 7], cities[index_cities, 8], cities[index_cities, 9])
city[city == "=PuertoRico=Vieques=Culebra="] = "=PuertoRico=Culebra="
city[city == "=LakeOkeechobee="] = "=LakeOkeechobee=LakeOkeechobee="
lst = strsplit(city, "=")
city_origin = sapply(lst, "[[", 2)
city_destination = sapply(lst, "[[", 3)
city_warning = (cities[index_cities, 1])
name = rep(name[-length(name)], reps)
code = rep(code[-length(code)], reps)
date = rep(date[-length(date)], reps)
hour = rep(hour[-length(hour)], reps)
#get rid of improper coding
city = paste0(cities[index_cities, 2], cities[index_cities, 3], cities[index_cities, 4], cities[index_cities, 5], cities[index_cities, 6], cities[index_cities, 7], cities[index_cities, 8], cities[index_cities, 9])
city[city == "=PuertoRico=Vieques=Culebra="] = "=PuertoRico=Culebra="
city[city == "=LakeOkeechobee="] = "=LakeOkeechobee=LakeOkeechobee="
lst = strsplit(city, "=")
city_origin = sapply(lst, "[[", 2)
city_destination = sapply(lst, "[[", 3)
city_warning = (cities[index_cities, 1])
name = rep(name[-length(name)], reps)
#now clean up data to look like what we want
index_cities = grep("=", cities[, 2])
number_index_list = gregexpr("[0-9]", cities[,2])
number_index = which(sapply(number_index_list, "[[", 1) == 1)
reps = diff(number_index) - 1
code = cities[number_index, 7]
date = paste0(cities[number_index, 1], "/", cities[number_index, 2], "/", cities[number_index, 3])
name = cities[number_index, 5]
hour = cities[number_index, 4]
#Parsing Data for Watchzone from NHC
cities = read.table("../data/wwpts_us.txt", fill = TRUE, col.names = rep("V", 10))
#now clean up data to look like what we want
index_cities = grep("=", cities[, 2])
number_index_list = gregexpr("[0-9]", cities[,2])
number_index = which(sapply(number_index_list, "[[", 1) == 1)
reps = diff(number_index) - 1
code = cities[number_index, 7]
date = paste0(cities[number_index, 1], "/", cities[number_index, 2], "/", cities[number_index, 3])
name = cities[number_index, 5]
hour = cities[number_index, 4]
#get rid of improper coding
city = paste0(cities[index_cities, 2], cities[index_cities, 3], cities[index_cities, 4], cities[index_cities, 5], cities[index_cities, 6], cities[index_cities, 7], cities[index_cities, 8], cities[index_cities, 9])
city[city == "=PuertoRico=Vieques=Culebra="] = "=PuertoRico=Culebra="
city[city == "=LakeOkeechobee="] = "=LakeOkeechobee=LakeOkeechobee="
lst = strsplit(city, "=")
city_origin = sapply(lst, "[[", 2)
city_destination = sapply(lst, "[[", 3)
city_warning = (cities[index_cities, 1])
name = rep(name[-length(name)], reps)
code = rep(code[-length(code)], reps)
date = rep(date[-length(date)], reps)
hour = rep(hour[-length(hour)], reps)
#Create final dataframe for the watchzone data
final_df = data.frame(code = code, name = name, date = date, hour = hour, city_origin = city_origin, city_destination = city_destination, warning = city_warning)
#Add geocoded variables
path = "../data/geocode_raw.csv"
geocoded_df = read.csv(path, header = TRUE)
final_df$origin_lat = geocoded_df$origin_lat
final_df$origin_long = geocoded_df$origin_long
final_df$destin_lat = geocoded_df$destin_lat
final_df$destin_long = geocoded_df$destin_long
corrected = function(city, lat, long) {
city = tolower(city)
final_df$origin_lat[tolower(final_df$city_origin) == city] = lat
final_df$origin_long[tolower(final_df$city_origin) == city] = long
final_df$destin_lat[tolower(final_df$city_destination) == city] = lat
final_df$destin_long[tolower(final_df$city_destination) == city] = long
return(final_df)
}
#Corrected
final_df = corrected("BAYPORT", 28.54306, -82.64401)
final_df = corrected("FLAMINGO", 25.14179, -80.92534)
final_df = corrected("VENICE", 27.09977, -82.45426)
final_df = corrected("FREEPORT", 30.51572, -86.13620)
final_df = corrected("CAMERON", 29.79770, -93.32520)
final_df = corrected("MOBILE", 30.69540, -88.03990)
final_df = corrected("VERMILIONBAY", 29.71965, -91.97623)
final_df = corrected("KEYWEST", 25.74590, -80.55500)
final_df = corrected("DRYTORTUGAS", 26.14200, -81.79480) #Just the island is weird
final_df = corrected("BAFFINBAY", 27.26700, -97.58210)
final_df = corrected("SARGENT", 28.83530, -95.66470)
final_df = corrected("OCEANREEF", 25.31170, -80.27940)
final_df = corrected("MISSISSIPPIRIVER", 29.16690, -89.25030)
final_df = corrected("ROCKPORT", 28.02060, -97.05440)
final_df = corrected("ROCKPORT", 28.02060, -97.05440)
final_df = corrected("SABINERIVER", 30.10236, -93.74420)
final_df = corrected("CAPEANN", 42.61590, -70.66200)
final_df = corrected("CAPELOOKOUT", 34.60530, -76.53670)
final_df = corrected("BRUNSWICK", 31.15000, -81.49150)
final_df = corrected("SAINTMARKS", 30.16100, -84.20630)
final_df = corrected("FENWICKISLAND", 38.46230, -75.05130)
final_df = corrected("SANDYHOOK", 41.43330, -73.98850)
final_df = corrected("CHATHAM", 41.68210, -69.95980)
final_df = corrected("STUART", 27.19750, -80.25280)
final_df = corrected("NC/VABORDER", 36.51880, -75.91990)
final_df = corrected("OregonInletI/PSAS", 36.51880, -75.91990)
final_df = corrected("NC/VABorderI/PSAS", 36.51880, -75.91990)
final_df = corrected("OceanReefI/FB", 25.31590, -80.27990)
final_df = corrected("FlaglerBeachI/LO", 29.47500, -81.12700)
final_df = corrected("StAugustineI/LO", 29.47500, -81.12700)
final_df = corrected("FloridaCity", 27.66480, -81.51580)
final_df = corrected("Englewood", 26.96200, -82.35260)
c_df = final_df[(final_df$warning == 5 | final_df$warning == 6), ]
#Helper clean up data file functions
#First two functions for regular expression matching
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
substrLeft = function(x, n){
substr(x, 1, n)
}
#This function is to extract the relevant best track line data for any specific hurricane name we desire
best_track_line = function(name, year, idf) {
name = tolower(name)
index = which(tolower(best_track$V2) == name)
start = index[which(substrRight(best_track$V1[index], 4) == year)]
hurricane = grep("[A-Z]", best_track$V2)
end = hurricane[which(hurricane == start) + 1]
in_df = best_track[start:(end-1), ]
in_df = in_df[-1, ]
date = as.character(idf$date)
in_date = substr(date, nchar(date) - 6, nchar(date) -5)
dex = which(substrRight(in_df$V1, 2) == in_date)
in_df_1 = in_df[1:dex[length(dex)], ]
x = substrLeft(in_df$V6, 4); y = substrLeft(in_df$V5, 4); x = gsub("[^0-9\\.]", "", x); y = gsub("[^0-9\\.]", "", y)
x = -as.numeric(x); y = as.numeric(y)
bt_df = data.frame(x = x, y = y, category = in_df$category)
return(bt_df)
}
#This function is to clean up the hurricane dataset the way we want
cleanup_df = function(name, year) {
name = tolower(name)
index = which(tolower(c_df$name) == name)
l = strsplit(as.character(c_df$date[index]), "/")
final_index = which(sapply(l, "[[", 3) == year)
final_index = index[final_index]
df = c_df[final_index, ]
a = unique(df$date)
lst = list()
for (i in 1:length(a)) {
l = which(df$date == a[i])
d = df[l, ]
l = unique(d$hour)
for(j in 1:length(l)) {
aa = which(d$hour == l[j])
if (length(aa) == 1) {
d[aa, ] = d[aa, ]
}
if (length(aa) != 1) {
dist = (d$origin_lat[aa] - d$destin_lat[aa])^2 + (d$origin_long[aa] - d$destin_long[aa])^2
chosen = which.max(dist)
index = which(aa != aa[chosen])
d = d[-c(aa[index]), ]
}
}
lst[[i]] = d
}
df = ldply(lst, data.frame)
return(df)
}
#us <- getData('GADM', country = 'USA', level = 1)
#a = makegrid(us, n = 1000000)
#grid = SpatialPoints(a, proj4string = CRS(proj4string(us)))
#grid = grid[us, ]
#grid = as.data.frame(grid)
library(maps); library(gridExtra); library(ggmap); library(ggplot2); library(plyr); library(raster); library(RColorBrewer); library(maptools); library(rgeos); library(sp); library(rgdal); library(geosphere); library(stringi); library(data.table)
#Parsing Data for Best Track Line from NHC
best_track = fread("https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt", blank.lines.skip = TRUE, header = FALSE, fill = TRUE)
#Create variable for recording category of hurricanes
best_track$category = vector()
best_track$category[best_track$V7 > 64] = 1
best_track$category[best_track$V7 > 83] = 2
best_track$category[best_track$V7 > 96] = 3
best_track$category[best_track$V7 > 113] = 4
best_track$category[best_track$V7 > 137] = 5
best_track$category[is.na(best_track$category)] = 0
#Parsing Data for Watchzone from NHC
cities = read.table("../data/wwpts_us.txt", fill = TRUE, col.names = rep("V", 10))
#now clean up data to look like what we want
index_cities = grep("=", cities[, 2])
number_index_list = gregexpr("[0-9]", cities[,2])
number_index = which(sapply(number_index_list, "[[", 1) == 1)
reps = diff(number_index) - 1
code = cities[number_index, 7]
date = paste0(cities[number_index, 1], "/", cities[number_index, 2], "/", cities[number_index, 3])
name = cities[number_index, 5]
hour = cities[number_index, 4]
#get rid of improper coding
city = paste0(cities[index_cities, 2], cities[index_cities, 3], cities[index_cities, 4], cities[index_cities, 5], cities[index_cities, 6], cities[index_cities, 7], cities[index_cities, 8], cities[index_cities, 9])
city[city == "=PuertoRico=Vieques=Culebra="] = "=PuertoRico=Culebra="
city[city == "=LakeOkeechobee="] = "=LakeOkeechobee=LakeOkeechobee="
lst = strsplit(city, "=")
city_origin = sapply(lst, "[[", 2)
city_destination = sapply(lst, "[[", 3)
city_warning = (cities[index_cities, 1])
name = rep(name[-length(name)], reps)
code = rep(code[-length(code)], reps)
date = rep(date[-length(date)], reps)
hour = rep(hour[-length(hour)], reps)
city_warning
#Create final dataframe for the watchzone data
final_df = data.frame(code = code, name = name, date = date, hour = hour, city_origin = city_origin, city_destination = city_destination, warning = city_warning)
#Add geocoded variables
path = "../data/geocode_raw.csv"
geocoded_df = read.csv(path, header = TRUE)
final_df$origin_lat = geocoded_df$origin_lat
final_df$origin_long = geocoded_df$origin_long
final_df$destin_lat = geocoded_df$destin_lat
final_df$destin_long = geocoded_df$destin_long
corrected = function(city, lat, long) {
city = tolower(city)
final_df$origin_lat[tolower(final_df$city_origin) == city] = lat
final_df$origin_long[tolower(final_df$city_origin) == city] = long
final_df$destin_lat[tolower(final_df$city_destination) == city] = lat
final_df$destin_long[tolower(final_df$city_destination) == city] = long
return(final_df)
}
#Corrected
final_df = corrected("BAYPORT", 28.54306, -82.64401)
final_df = corrected("FLAMINGO", 25.14179, -80.92534)
final_df = corrected("VENICE", 27.09977, -82.45426)
final_df = corrected("FREEPORT", 30.51572, -86.13620)
final_df = corrected("CAMERON", 29.79770, -93.32520)
final_df = corrected("MOBILE", 30.69540, -88.03990)
final_df = corrected("VERMILIONBAY", 29.71965, -91.97623)
final_df = corrected("KEYWEST", 25.74590, -80.55500)
final_df = corrected("DRYTORTUGAS", 26.14200, -81.79480) #Just the island is weird
final_df = corrected("BAFFINBAY", 27.26700, -97.58210)
final_df = corrected("SARGENT", 28.83530, -95.66470)
final_df = corrected("OCEANREEF", 25.31170, -80.27940)
final_df = corrected("MISSISSIPPIRIVER", 29.16690, -89.25030)
final_df = corrected("ROCKPORT", 28.02060, -97.05440)
final_df = corrected("ROCKPORT", 28.02060, -97.05440)
final_df = corrected("SABINERIVER", 30.10236, -93.74420)
final_df = corrected("CAPEANN", 42.61590, -70.66200)
final_df = corrected("CAPELOOKOUT", 34.60530, -76.53670)
final_df = corrected("BRUNSWICK", 31.15000, -81.49150)
final_df = corrected("SAINTMARKS", 30.16100, -84.20630)
final_df = corrected("FENWICKISLAND", 38.46230, -75.05130)
final_df = corrected("SANDYHOOK", 41.43330, -73.98850)
final_df = corrected("CHATHAM", 41.68210, -69.95980)
final_df = corrected("STUART", 27.19750, -80.25280)
final_df = corrected("NC/VABORDER", 36.51880, -75.91990)
final_df = corrected("OregonInletI/PSAS", 36.51880, -75.91990)
final_df = corrected("NC/VABorderI/PSAS", 36.51880, -75.91990)
final_df = corrected("OceanReefI/FB", 25.31590, -80.27990)
final_df = corrected("FlaglerBeachI/LO", 29.47500, -81.12700)
final_df = corrected("StAugustineI/LO", 29.47500, -81.12700)
final_df = corrected("FloridaCity", 27.66480, -81.51580)
final_df = corrected("Englewood", 26.96200, -82.35260)
c_df = final_df[(final_df$warning == 5 | final_df$warning == 6), ]
#Helper clean up data file functions
#First two functions for regular expression matching
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
substrLeft = function(x, n){
substr(x, 1, n)
}
#This function is to extract the relevant best track line data for any specific hurricane name we desire
best_track_line = function(name, year, idf) {
name = tolower(name)
index = which(tolower(best_track$V2) == name)
start = index[which(substrRight(best_track$V1[index], 4) == year)]
hurricane = grep("[A-Z]", best_track$V2)
end = hurricane[which(hurricane == start) + 1]
in_df = best_track[start:(end-1), ]
in_df = in_df[-1, ]
date = as.character(idf$date)
in_date = substr(date, nchar(date) - 6, nchar(date) -5)
dex = which(substrRight(in_df$V1, 2) == in_date)
in_df_1 = in_df[1:dex[length(dex)], ]
x = substrLeft(in_df$V6, 4); y = substrLeft(in_df$V5, 4); x = gsub("[^0-9\\.]", "", x); y = gsub("[^0-9\\.]", "", y)
x = -as.numeric(x); y = as.numeric(y)
bt_df = data.frame(x = x, y = y, category = in_df$category)
return(bt_df)
}
#This function is to clean up the hurricane dataset the way we want
cleanup_df = function(name, year) {
name = tolower(name)
index = which(tolower(c_df$name) == name)
l = strsplit(as.character(c_df$date[index]), "/")
final_index = which(sapply(l, "[[", 3) == year)
final_index = index[final_index]
df = c_df[final_index, ]
a = unique(df$date)
lst = list()
for (i in 1:length(a)) {
l = which(df$date == a[i])
d = df[l, ]
l = unique(d$hour)
for(j in 1:length(l)) {
aa = which(d$hour == l[j])
if (length(aa) == 1) {
d[aa, ] = d[aa, ]
}
if (length(aa) != 1) {
dist = (d$origin_lat[aa] - d$destin_lat[aa])^2 + (d$origin_long[aa] - d$destin_long[aa])^2
chosen = which.max(dist)
index = which(aa != aa[chosen])
d = d[-c(aa[index]), ]
}
}
lst[[i]] = d
}
df = ldply(lst, data.frame)
return(df)
}
#us <- getData('GADM', country = 'USA', level = 1)
#a = makegrid(us, n = 1000000)
#grid = SpatialPoints(a, proj4string = CRS(proj4string(us)))
#grid = grid[us, ]
#grid = as.data.frame(grid)
#Database for all hurricanes - Extracting all the hurricane names and dates from the NHC data
#Hurricane names:
hurricane_names = unique(c_df$name)
#Extract dates
extract_date = function(hurricane, data = c_df) {
index = which(c_df[, 2] == hurricane)
index = index[1]
out = c_df[, 3][index]
a = substrRight(x = as.character(out), n = 4)
return(a)
}
dates = vector(length = 0)
for (i in 1:length(hurricane_names)) {
dates[i] = extract_date(hurricane = hurricane_names[i], data = c_df)
}
hurricane_names = as.character(hurricane_names)
get_landfall_date = function(name, year) {
name = tolower(name)
index = which(tolower(best_track$V2) == name)
start = index[which(substrRight(best_track$V1[index], 4) == year)]
hurricane = grep("[A-Z]", best_track$V2)
end = hurricane[which(hurricane == start) + 1]
in_df = best_track[start:(end-1), ]
in_df = in_df[-1, ]
in_date = (in_df$V1[which(in_df$V3 == "L")])
in_date = as.Date(in_date, "%Y%m%d")
return(in_date)
}
dates
#Missing hurricanes
#i = 77 take out because eighteen is not here
hurricane_names = hurricane_names[-77]
dates = dates[-77]
hurricane_names = hurricane_names[-96]
dates = dates[-96]
landfall_date = vector()
for (i in 1:100) {
landfall_date[i] = as.character(get_landfall_date(name = hurricane_names[i], year = dates[i])[1])
}
get_landfall_date("KATRINA", 2005, ind = 1)
landfall <- data.frame()
for (i in 1:100) {
df=data.frame()
ld=get_landfall_date(hurricane_names[i], dates[i])
name = hurricane_names[i]
for (i in 1:length(ld)){
df[nrow(df)+1, 1:2] = list(paste0(as.character(name), i), ld[i])
}
landfall = rbind(landfall, df)
}
landfall <- data.frame()
for (i in 1:100) {
df=data.frame()
ld=get_landfall_date(hurricane_names[i], dates[i])
name = hurricane_names[i]
for (i in 1:length(ld)){
df[nrow(df)+1, 1:2] = list(paste0(as.character(name), i), ld[i])
}
landfall = rbind(landfall, df)
}
names(landfall)=c('hurricanes','landfalldate')
landfall%>%filter(!is.na(landfalldate))
